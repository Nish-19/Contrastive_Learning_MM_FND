{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/sda/rina_1921cs13/Nischal/NovFake/data/'\n",
    "text_arr = np.load(os.path.join(data_dir, 'text_array.npy'))\n",
    "labels_arr = np.load(os.path.join(data_dir, 'labels.npy')).squeeze() # 0 fake, 1 real\n",
    "ids_arr = np.load(os.path.join(data_dir, 'ids.npy')).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr = np.load(os.path.join(data_dir, 'image_array.npy')).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Target Shape (11766, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "num_images, sources, width, height, num_channels = image_arr.shape\n",
    "img_data_reshape = np.reshape(image_arr, newshape=(num_images, sources, num_channels, width, height))\n",
    "img_data_target = img_data_reshape[:,0,:,:,:] # Don't convert to GPU\n",
    "print('New Target Shape', img_data_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    }
   ],
   "source": [
    "# Clip (Image/Text Model)\n",
    "model_img = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512,)\n",
      "(512,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "sample_img_embed = model_img.encode(Image.fromarray(img_data_target[0].astype('uint8'), 'RGB'))\n",
    "sample_txt_embed = model_img.encode(text_arr[0][0])\n",
    "sample_comb_embed = np.concatenate([sample_img_embed, sample_txt_embed])\n",
    "print(type(sample_img_embed))\n",
    "print(sample_img_embed.shape)\n",
    "print(sample_txt_embed.shape)\n",
    "print(sample_comb_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "#NOTE: Get all embeddings\n",
    "all_embeds = []\n",
    "for i in range(len(text_arr)):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    img_embed = model_img.encode(Image.fromarray(img_data_target[i].astype('uint8'), 'RGB'))\n",
    "    try:\n",
    "        txt_embed = model_img.encode(text_arr[i][0])\n",
    "    except:\n",
    "        txt_embed = model_img.encode(text_arr[1671][0][0:380])\n",
    "    comb_embed = np.concatenate([img_embed, txt_embed])\n",
    "    all_embeds.append(comb_embed)\n",
    "embed_arr = np.array(all_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "np.save('../Data/clip_embed', embed_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Clustering models\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=43).fit(embed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 570, 6: 950, 3: 1092, 7: 452, 2: 1778, 0: 2034, 8: 1244, 9: 607, 5: 1544, 4: 1495}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cluster_labels = kmeans.labels_\n",
    "cluster_counts = dict(Counter(cluster_labels.tolist()))\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster labels\n",
    "np.save('../Data/nis_event_labels', cluster_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "112ac2046fa01f929d29fd747457323c8422411859b530c12136f6127f223c24"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('newnisbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
