{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_number = \"0\" # Choose either 0 or 1\n",
    "os.environ['CUDA_ENVIRONMENT_DEVICES'] = gpu_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import asarray,zeros\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW, get_linear_schedule_with_warmup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import timm\n",
    "from losses import SupConLoss\n",
    "from torchlars import LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = \"cuda:\" + gpu_number\n",
    "    device = torch.device(device_name)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\") # Force CPU\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demark_dict = {'Snp':{'start':0, 'end':1663},\n",
    "                'Rtr':{'start':1664, 'end':2630},\n",
    "                'Rcv':{'start':2631, 'end':4716},\n",
    "                'Tcn':{'start':4717, 'end':11765}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name cvalidate_nv_em_ce_rbert_full\n",
      "Source shape (11766, 1280)\n",
      "Target shape (11766, 1280)\n",
      "Emotion Shape (11766, 128)\n",
      "Labels shape (11766,)\n"
     ]
    }
   ],
   "source": [
    "# Loading Choice\n",
    "base_model_name = 'rbert' # choice 'vbert' or 'rbert'\n",
    "dataset_split = 'full' # 'full' or 'faux' or 'ticnn' or 'recov'\n",
    "model_name = 'cvalidate'\n",
    "if base_model_name =='rbert':\n",
    "    source_multimodal_data_full = np.load(\"../data/source_multimodal_out.npy\")\n",
    "    target_multimodal_data_full = np.load(\"../data/target_multimodal_out.npy\")\n",
    "    labels_data_full = np.load(\"../data/labels.npy\").squeeze(1)\n",
    "    contrastive_model_path = 'saved_models/contrast_head_rbert_lr_5_ep_1000.pt'\n",
    "    model_name = 'cvalidate_nv_em_ce_rbert'\n",
    "elif base_model_name == 'vbert':\n",
    "    source_multimodal_data_full = np.load(\"../data/source_mm_vbert.npy\")\n",
    "    target_multimodal_data_full = np.load(\"../data/target_mm_vbert.npy\")\n",
    "    labels_data_full = np.load(\"../data/labels.npy\").squeeze(1)\n",
    "    contrastive_model_path = 'saved_models/contrast_head_vbert_lr_5_ep_1000.pt'\n",
    "    model_name = 'cvalidate_nv_em_ce_vbert'\n",
    "\n",
    "emotion_arr = np.load('../data/emotion_reprs_new.npy')\n",
    "\n",
    "if dataset_split == 'full':\n",
    "    source_multimodal_data = source_multimodal_data_full\n",
    "    target_multimodal_data = target_multimodal_data_full\n",
    "    labels_data = labels_data_full\n",
    "    emotion_data = emotion_arr\n",
    "    model_name = model_name + '_full'\n",
    "elif dataset_split == 'faux':\n",
    "    src_snoopes = source_multimodal_data_full[demark_dict['Snp']['start']:demark_dict['Snp']['end'],:]\n",
    "    tar_snoopes = target_multimodal_data_full[demark_dict['Snp']['start']:demark_dict['Snp']['end'],:]\n",
    "    lab_snoopes = labels_data_full[demark_dict['Snp']['start']:demark_dict['Snp']['end']]\n",
    "    emotion_snoopes = emotion_arr[demark_dict['Snp']['start']:demark_dict['Snp']['end']]\n",
    "    src_rtr = source_multimodal_data_full[demark_dict['Rtr']['start']:demark_dict['Rtr']['end'],:]\n",
    "    tar_rtr = target_multimodal_data_full[demark_dict['Rtr']['start']:demark_dict['Rtr']['end'],:]\n",
    "    lab_tar = labels_data_full[demark_dict['Rtr']['start']:demark_dict['Rtr']['end']]\n",
    "    emotion_rtr = emotion_arr[demark_dict['Rtr']['start']:demark_dict['Rtr']['end']]\n",
    "    source_multimodal_data = np.concatenate((src_snoopes, src_rtr), axis=0)\n",
    "    target_multimodal_data = np.concatenate((tar_snoopes, tar_rtr), axis=0)\n",
    "    emotion_data = np.concatenate((emotion_snoopes, emotion_rtr), axis=0)\n",
    "    labels_data = np.concatenate((lab_snoopes, lab_tar), axis=0)\n",
    "    model_name = model_name + '_faux'\n",
    "elif dataset_split == 'recov':\n",
    "    source_multimodal_data = source_multimodal_data_full[demark_dict['Rcv']['start']:demark_dict['Rcv']['end'],:]\n",
    "    target_multimodal_data = target_multimodal_data_full[demark_dict['Rcv']['start']:demark_dict['Rcv']['end'],:]\n",
    "    labels_data = labels_data_full[demark_dict['Rcv']['start']:demark_dict['Rcv']['end']]\n",
    "    emotion_data = emotion_arr[demark_dict['Rcv']['start']:demark_dict['Rcv']['end']]\n",
    "    model_name = model_name + '_recov'\n",
    "elif dataset_split == 'ticnn':\n",
    "    source_multimodal_data = source_multimodal_data_full[demark_dict['Tcn']['start']:demark_dict['Tcn']['end'],:]\n",
    "    target_multimodal_data = target_multimodal_data_full[demark_dict['Tcn']['start']:demark_dict['Tcn']['end'],:]\n",
    "    labels_data = labels_data_full[demark_dict['Tcn']['start']:demark_dict['Tcn']['end']]\n",
    "    emotion_data = emotion_arr[demark_dict['Tcn']['start']:demark_dict['Tcn']['end']]\n",
    "    model_name = model_name + '_ticnn'\n",
    "\n",
    "#TODO: Printing the shape of the model\n",
    "print('Model name', model_name)\n",
    "print('Source shape', source_multimodal_data.shape)\n",
    "print('Target shape', target_multimodal_data.shape)\n",
    "print('Emotion Shape', emotion_data.shape)\n",
    "print('Labels shape', labels_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5793, 0.4207], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#TODO: Get Class weights\n",
    "from collections import Counter \n",
    "weights = Counter(labels_data)\n",
    "fake_weight = weights[1]/(weights[0]+weights[1])\n",
    "real_weight = weights[0]/(weights[0]+weights[1])\n",
    "class_weights = torch.tensor([fake_weight, real_weight], device=device)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Resnet+BERT Multimodal data\n",
    "# source_multimodal_arr = np.load(\"../data/source_multimodal_out.npy\")\n",
    "# target_multimodal_arr = np.load(\"../data/target_multimodal_out.npy\")\n",
    "# print(\"Source shape\", source_multimodal_arr.shape)\n",
    "# print(\"Target shape\", target_multimodal_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Import Visual BERT Multimodal data\n",
    "# source_multimodal_arr = np.load(\"../data/source_mm_vbert.npy\")\n",
    "# target_multimodal_arr = np.load(\"../data/target_mm_vbert.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Import source data for emotion\n",
    "# # img_data = np.load(\"../data/image_array.npy\")\n",
    "# # num_images, sources, width, height, num_channels = img_data.shape\n",
    "# # img_data_reshape = np.reshape(img_data, newshape=(num_images, sources, num_channels, width, height))\n",
    "# # img_data_source = torch.tensor(img_data_reshape[:,1,:,:,:]) \n",
    "# # print('New Source Shape', img_data_source.shape)\n",
    "# emotion_arr = np.load('../data/emotion_reprs_new.npy')\n",
    "# print('Emotion array shape', emotion_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # New features\n",
    "# diff_arr = source_multimodal_arr - target_multimodal_arr\n",
    "# mul_diff_arr = source_multimodal_arr * diff_arr\n",
    "# print(\"Source shape\", diff_arr.shape)\n",
    "# print(\"Target shape\", mul_diff_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Considering only the text parts - #TODO: Comment if not necessary\n",
    "# source_multimodal_arr = source_multimodal_arr[:,768:] # Only BERT\n",
    "# target_multimodal_arr = target_multimodal_arr[:,768:] # Only BERT\n",
    "# print(\"Source shape\", source_multimodal_arr.shape)\n",
    "# print(\"Target shape\", target_multimodal_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape torch.Size([11766, 1280])\n",
      "Target shape torch.Size([11766, 1280])\n",
      "Emotion Source shape torch.Size([11766, 128])\n",
      "Labels shape torch.Size([11766])\n"
     ]
    }
   ],
   "source": [
    "# NOTE: ALL features\n",
    "source_multimodal_tensor = torch.tensor(source_multimodal_data)\n",
    "target_multimodal_tensor = torch.tensor(target_multimodal_data)\n",
    "emotion_source_tensor = torch.tensor(emotion_data)\n",
    "labels_tensor = torch.tensor(labels_data, dtype=torch.long)\n",
    "print(\"Source shape\", source_multimodal_tensor.shape)\n",
    "print(\"Target shape\", target_multimodal_tensor.shape)\n",
    "print(\"Emotion Source shape\", emotion_source_tensor.shape)\n",
    "print(\"Labels shape\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NOTE: New features (NOT GOOD)\n",
    "# diff_arr = torch.tensor(diff_arr, device=device)\n",
    "# mul_diff_arr = torch.tensor(mul_diff_arr, device=device)\n",
    "# print(\"Source shape\", diff_arr.shape)\n",
    "# print(\"Target shape\", mul_diff_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the label\n",
    "# labels_data = np.load(\"../data/labels.npy\")\n",
    "# labels_tensor = torch.tensor(labels_data, dtype=torch.long).squeeze(-1)\n",
    "# print('Labels tensor shape', labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add Pytorch DataLoader\n",
    "def get_data_loader(batch_size, target_input, source_input, emotion_input, labels, split_type='train'):\n",
    "\tdata = TensorDataset(target_input, source_input, emotion_input, labels)\n",
    "\tif split_type == 'train':\n",
    "\t\tsampler = RandomSampler(data)\n",
    "\telif split_type == 'val':\n",
    "\t\tsampler = SequentialSampler(data)\n",
    "\tdataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\treturn data, sampler, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "TRAIN: (9412,) TEST: (2354,)\n",
      "TRAIN: (9413,) TEST: (2353,)\n",
      "TRAIN: (9413,) TEST: (2353,)\n",
      "TRAIN: (9413,) TEST: (2353,)\n",
      "TRAIN: (9413,) TEST: (2353,)\n"
     ]
    }
   ],
   "source": [
    "#TODO: Get K-Fold Split\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "kf.get_n_splits(source_multimodal_tensor)\n",
    "print(kf)\n",
    "# Obtaining split data\n",
    "for train_index, test_index in kf.split(source_multimodal_tensor):\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Old features\n",
    "# train_tar, test_tar, train_src, test_src, train_emotion, test_emotion, train_labels, test_labels = train_test_split(target_multimodal_tensor, source_multimodal_tensor, emotion_source_tensor, labels_tensor, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# train_data, train_sampler, train_dataloader = get_data_loader(batch_size, train_tar, train_src, train_emotion, train_labels, 'train')\n",
    "# test_data, test_sampler, test_dataloader = get_data_loader(batch_size, test_tar, test_src, test_emotion, test_labels, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model imported from the previous network\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, initial_dim):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.project_1 = nn.Linear(initial_dim, 512, bias=True)\n",
    "        self.project_2 = nn.Linear(512, 128, bias=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    def forward(self, multimodal_input):\n",
    "        contrast_space = self.project_2(self.project_1(multimodal_input))\n",
    "        normalize_contrast = F.normalize(contrast_space, dim=2)\n",
    "        return normalize_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Novelty based Contrastive Model\n",
    "class NoveltyModule(nn.Module):\n",
    "    def __init__(self, initial_dim):\n",
    "        super(NoveltyModule, self).__init__()\n",
    "        self.contrastive_model = ContrastiveModel(initial_dim) # For generic model\n",
    "        # self.contrastive_model = ContrastiveModelVisualBERT(initial_dim) # For visual BERT only\n",
    "        # self.contrastive_model.load_state_dict(torch.load('saved_models/contrast_head_visualbert_lr_5_ep_1000.pt')) # For vbert\n",
    "        # self.contrastive_model.load_state_dict(torch.load('saved_models/contrast_head_lr_5_ep_1000.pt')) # For rbert\n",
    "        self.contrastive_model.load_state_dict(torch.load(contrastive_model_path)) # For rbert\n",
    "        for param in self.contrastive_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.reduce_1 = nn.Linear((512)*3, 512)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.logits_layer = nn.Linear(512, 2)\n",
    "    def forward(self, target_input, source_input):\n",
    "        fixed_target = self.contrastive_model.project_1(target_input)\n",
    "        fixed_source = self.contrastive_model.project_1(source_input)\n",
    "        add_op = fixed_target + fixed_source\n",
    "        sub_op = fixed_target - fixed_source\n",
    "        mul_op = fixed_target * fixed_source\n",
    "        combine_t_s = torch.cat((add_op, sub_op, mul_op), 1)\n",
    "        reduce_output = self.tanh1(self.reduce_1(combine_t_s)) # 512 dimension\n",
    "        return reduce_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Emotion based Model\n",
    "class ResNetBottom(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ResNetBottom, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class EmotionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionModule, self).__init__()\n",
    "        self.vision_base_model = timm.create_model('resnet50', pretrained=True)\n",
    "        self.vision_model_head = ResNetBottom(self.vision_base_model)\n",
    "        self.project_1 = nn.Linear(2048, 1024, bias=True)\n",
    "        self.project_2 = nn.Linear(1024, 512, bias=True)\n",
    "        self.project_3 = nn.Linear(512, 128, bias=True)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.drop1 = nn.Dropout()\n",
    "        self.drop2 = nn.Dropout()\n",
    "        self.drop3 = nn.Dropout()\n",
    "        self.classification = nn.Linear(128, 2, bias=True)\n",
    "    def forward(self, img_features):\n",
    "        with torch.no_grad():\n",
    "            img_out = self.vision_model_head(img_features)\n",
    "        emotion_features = self.tanh3(self.project_3(self.tanh2(self.project_2(self.tanh1(self.project_1(img_out))))))\n",
    "        return emotion_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Defin Combine Novelty-Emotion Model for classification\n",
    "class FinalClassifier(nn.Module):\n",
    "    def __init__(self, initial_dim):\n",
    "        super(FinalClassifier, self).__init__()\n",
    "        self.novelty_module = NoveltyModule(initial_dim) # For novelty model\n",
    "        # self.emotion_module = EmotionModule()\n",
    "        # self.emotion_module.load_state_dict(torch.load('../emotion/saved_models/emo_combine_res50_lr_3e-05_val_loss_0.59487_ep_61.pt'))\n",
    "        self.reduce_1 = nn.Linear(640, 512, bias=True)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.reduce_2 = nn.Linear(512, 128, bias=True)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.logits_layer = nn.Linear(128, 2)\n",
    "    def forward(self, target_input, source_input, emotion_input):\n",
    "        # Novelty Representations\n",
    "        novelty_reprs = self.novelty_module(target_input, source_input)\n",
    "        emotion_reprs = emotion_input\n",
    "        combine_n_e = torch.cat((novelty_reprs, emotion_reprs), 1) # 640\n",
    "        reduce_output_1 = self.tanh1(self.reduce_1(combine_n_e.float())) # 512 dimension\n",
    "        reduce_output_2 = self.tanh2(self.reduce_2(reduce_output_1.float())) # 128 dimension\n",
    "        logits = self.logits_layer(reduce_output_2.float()) # 2 dimension\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry-Run Classification model\n",
    "initial_dim = source_multimodal_tensor.shape[1]\n",
    "# initial_dim = diff_arr.shape[1]\n",
    "class_model = FinalClassifier(initial_dim).to(device) # For old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "def get_optimizer_scheduler(name, model, train_dataloader_len, epochs, lr_set):\n",
    "\tif name == \"Adam\":\n",
    "\t\toptimizer = AdamW(model.parameters(),\n",
    "                  lr = lr_set, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "\t\t)\n",
    "\telif name == \"LARS-SGD\":\n",
    "\t\tbase_optimizer = optim.SGD(model.parameters(), lr=lr_set, momentum=0.9)\n",
    "\t\toptimizer = LARS(optimizer=base_optimizer, eps=1e-8, trust_coef=0.001)\n",
    "\n",
    "\ttotal_steps = train_dataloader_len * epochs\n",
    "\n",
    "\t# Create the learning rate scheduler.\n",
    "\tscheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_warmup_steps = total_steps//2, # Default value in run_glue.py\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_training_steps = total_steps)\n",
    "\treturn optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the optimizer and scheduler\n",
    "epochs = 2\n",
    "lr = 3e-5 # Less LR\n",
    "# lr = 0.5\n",
    "iters_to_accumulate = 2\n",
    "name = \"Adam\"\n",
    "# name = \"LARS-SGD\"\n",
    "if base_model_name == 'vbert' and dataset_split == 'recov':\n",
    "    criterion = nn.CrossEntropyLoss(class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "# optimizer, scheduler = get_optimizer_scheduler(name, class_model, len(train_dataloader), epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Evaluating Loss ######################\n",
    "#######################################################\n",
    "def evaluate_loss(net, device, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for it, (target_inputs, source_inputs, emotion_inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "            target_inputs, source_inputs, emotion_inputs, labels = target_inputs.to(device), source_inputs.to(device), emotion_inputs.to(device), labels.to(device)\n",
    "            logits = net(target_inputs, source_inputs, emotion_inputs)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels).item() # initially it was logits.squeeze(-1)\n",
    "            count += 1\n",
    "    return mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Flat Accuracy Calculation ####################\n",
    "###############################################################\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "################ Validation Accuracy Calculation ####################\n",
    "###############################################################\n",
    "def evaluate_accuracy(model, device, validation_dataloader):\n",
    "\tmodel.eval()\n",
    "\t# Tracking variables \n",
    "\teval_loss, eval_accuracy = 0, 0\n",
    "\tnb_eval_steps, nb_eval_examples = 0, 0\n",
    "\t# Evaluate data for one epoch\n",
    "\tfor batch in validation_dataloader:\n",
    "\t    # Add batch to GPU\n",
    "\t    batch = tuple(t.to(device) for t in batch)\t    \n",
    "\t    # Unpack the inputs from our dataloader\n",
    "\t    b_t_inputs, b_s_inputs, b_e_inputs, b_labels = batch\t    \n",
    "\t    \n",
    "\t    # Telling the model not to compute or store gradients, saving memory and\n",
    "\t    # speeding up validation\n",
    "\t    with torch.no_grad(): \n",
    "\t    \t# Forward pass, calculate logit predictions.\n",
    "\t        # This will return the logits rather than the loss because we have\n",
    "\t        # not provided labels.\n",
    "\t    \tlogits = model(b_t_inputs, b_s_inputs, b_e_inputs)       \n",
    "\n",
    "\t    # Move logits and labels to CPU\n",
    "\t    logits = logits.detach().cpu().numpy()\n",
    "\t    label_ids = b_labels.to('cpu').numpy()\n",
    "\t    \n",
    "\t    # Calculate the accuracy for this batch of test sentences.\n",
    "\t    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\t    \n",
    "\t    # Accumulate the total accuracy.\n",
    "\t    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "\t    # Track the number of batches\n",
    "\t    nb_eval_steps += 1\n",
    "\taccuracy = eval_accuracy/nb_eval_steps\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n",
    "    best_loss = np.Inf\n",
    "    best_ep = 1\n",
    "    nb_iterations = len(train_loader)\n",
    "    print_every = nb_iterations // 5  # print the training loss 5 times per epoch\n",
    "    iters = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # Iterating over all epochs\n",
    "    for ep in range(epochs):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for it, (target_inputs, source_inputs, emotion_inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            # Converting to cuda tensors\n",
    "            target_inputs, source_inputs, emotion_inputs, labels = target_inputs.to(device), source_inputs.to(device), emotion_inputs.to(device), labels.to(device)\n",
    "    \t\t\n",
    "            # Obtaining the logits from the model\n",
    "            logits = net(target_inputs, source_inputs, emotion_inputs)\n",
    "            # print(logits.device)\n",
    "\n",
    "            # Computing loss\n",
    "            # print(logits.squeeze(-1).shape)\n",
    "            # print(labels.shape)\n",
    "            loss = criterion(logits.squeeze(-1), labels)\n",
    "            loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n",
    "\n",
    "            # Backpropagating the gradients\n",
    "            # Calls backward()\n",
    "            loss.backward()\n",
    "\n",
    "            if (it + 1) % iters_to_accumulate == 0:\n",
    "                # Optimization step\n",
    "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n",
    "                # otherwise, opti.step() is skipped.\n",
    "                opti.step()\n",
    "                # Adjust the learning rate based on the number of iterations.\n",
    "                lr_scheduler.step()\n",
    "                # Clear gradients\n",
    "                net.zero_grad()\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (it + 1) % print_every == 0:  # Print training loss information\n",
    "                print()\n",
    "                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n",
    "                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n",
    "        val_accuracy = evaluate_accuracy(net, device, val_loader)\n",
    "        print()\n",
    "        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n",
    "        print(\"Epoch {} complete! Validation Accuracy : {}\".format(ep+1, val_accuracy))\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n",
    "            print()\n",
    "            net_copy = copy.deepcopy(net)  # save a copy of the model\n",
    "            best_loss = val_loss\n",
    "            best_ep = ep + 1\n",
    "\n",
    "    # # Saving the model\n",
    "    # path_to_model='saved_models/{}_lr_{}_val_loss_{}_ep_{}.pt'.format(model_name, lr, round(best_loss, 5), best_ep)\n",
    "    # torch.save(net_copy.state_dict(), path_to_model)\n",
    "    # net.load_state_dict(torch.load(path_to_model)) # Re-Loading the best model\n",
    "    # print(\"The model has been saved in {}\".format(path_to_model))\n",
    "\n",
    "    del loss\n",
    "    torch.cuda.empty_cache()\n",
    "    return net, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prediction_dataloader, model, path_to_model, load = False):\n",
    "\t# Prediction on test set\n",
    "\tif load:\n",
    "\t\tprint(\"Loading the weights of the model...\")\n",
    "\t\tmodel.load_state_dict(torch.load(path_to_model))\n",
    "\n",
    "\tprint('Evaluating on the testset')\n",
    "\n",
    "\t# Put model in evaluation mode\n",
    "\tmodel.eval()\n",
    "\n",
    "\t# Tracking variables \n",
    "\tpredictions , true_labels = [], []\n",
    "\n",
    "\t# Predict \n",
    "\tfor batch in prediction_dataloader:\n",
    "\t  # Add batch to GPU\n",
    "\t  batch = tuple(t.to(device) for t in batch)\n",
    "\t  \n",
    "\t  # Unpack the inputs from our dataloader\n",
    "\t  b_t_inputs, b_s_inputs, b_e_inputs, b_labels = batch\n",
    "\t  \n",
    "\t  # Telling the model not to compute or store gradients, saving memory and \n",
    "\t  # speeding up prediction\n",
    "\t  with torch.no_grad():\n",
    "\t      # Forward pass, calculate logit predictions\n",
    "\t      logits = model(b_t_inputs, b_s_inputs, b_e_inputs)\n",
    "\n",
    "\t  # Move logits and labels to CPU\n",
    "\t  logits = logits.detach().cpu().numpy()\n",
    "\t  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "\t  pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\t  labels_flat = label_ids.flatten()\n",
    "\t  \n",
    "\t  # Store predictions and true labels\n",
    "\t  predictions.extend(pred_flat)\n",
    "\t  true_labels.extend(labels_flat)\n",
    "\treturn predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 12/74 [00:00<00:00, 118.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 0\n",
      "TRAIN: (9412,) TEST: (2354,)\n",
      "\n",
      "Iteration 14/74 of epoch 1 complete. Loss : 0.025911235317055668 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 52/74 [00:00<00:00, 124.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 28/74 of epoch 1 complete. Loss : 0.020001504038061415 \n",
      "\n",
      "Iteration 42/74 of epoch 1 complete. Loss : 0.020821807706462487 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 125.54it/s]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 56/74 of epoch 1 complete. Loss : 0.020666311162390878 \n",
      "\n",
      "Iteration 70/74 of epoch 1 complete. Loss : 0.02362994131233011 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 237.04it/s]\n",
      " 18%|█▊        | 13/74 [00:00<00:00, 123.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 complete! Validation Loss : 0.06568516065415583\n",
      "Epoch 1 complete! Validation Accuracy : 0.9851973684210527\n",
      "Best validation loss improved from inf to 0.06568516065415583\n",
      "\n",
      "\n",
      "Iteration 14/74 of epoch 2 complete. Loss : 0.02092042625216501 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 51/74 [00:00<00:00, 124.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 28/74 of epoch 2 complete. Loss : 0.019998134712555578 \n",
      "\n",
      "Iteration 42/74 of epoch 2 complete. Loss : 0.018987865253750767 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 123.03it/s]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 56/74 of epoch 2 complete. Loss : 0.01803063621212329 \n",
      "\n",
      "Iteration 70/74 of epoch 2 complete. Loss : 0.019135993772319386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 242.06it/s]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 complete! Validation Loss : 0.05826233543063465\n",
      "Epoch 2 complete! Validation Accuracy : 0.984375\n",
      "Best validation loss improved from 0.06568516065415583 to 0.05826233543063465\n",
      "\n",
      "Evaluating on the testset\n",
      "SPLIT 1\n",
      "TRAIN: (9413,) TEST: (2353,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 27/74 [00:00<00:00, 129.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 14/74 of epoch 1 complete. Loss : 0.01885822242391961 \n",
      "\n",
      "Iteration 28/74 of epoch 1 complete. Loss : 0.01947618235966989 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 66/74 [00:00<00:00, 128.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 42/74 of epoch 1 complete. Loss : 0.01754004797632141 \n",
      "\n",
      "Iteration 56/74 of epoch 1 complete. Loss : 0.016947347704055055 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 127.93it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 244.93it/s]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 70/74 of epoch 1 complete. Loss : 0.015239795536867209 \n",
      "\n",
      "Epoch 1 complete! Validation Loss : 0.04467553062070357\n",
      "Epoch 1 complete! Validation Accuracy : 0.9876644736842105\n",
      "Best validation loss improved from inf to 0.04467553062070357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 39/74 [00:00<00:00, 127.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 14/74 of epoch 2 complete. Loss : 0.014347264609698738 \n",
      "\n",
      "Iteration 28/74 of epoch 2 complete. Loss : 0.014099722728133202 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 64/74 [00:00<00:00, 125.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 42/74 of epoch 2 complete. Loss : 0.014680840939815556 \n",
      "\n",
      "Iteration 56/74 of epoch 2 complete. Loss : 0.015575812863452094 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 124.94it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 243.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 70/74 of epoch 2 complete. Loss : 0.017818639553817257 \n",
      "\n",
      "Epoch 2 complete! Validation Loss : 0.04456924533128346\n",
      "Epoch 2 complete! Validation Accuracy : 0.9833008861439313\n",
      "Best validation loss improved from 0.04467553062070357 to 0.04456924533128346\n",
      "\n",
      "Evaluating on the testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 14/74 [00:00<00:00, 130.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n",
      "TRAIN: (9413,) TEST: (2353,)\n",
      "\n",
      "Iteration 14/74 of epoch 1 complete. Loss : 0.019595781341195107 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 53/74 [00:00<00:00, 129.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 28/74 of epoch 1 complete. Loss : 0.017633090427677547 \n",
      "\n",
      "Iteration 42/74 of epoch 1 complete. Loss : 0.014155046515432852 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 66/74 [00:00<00:00, 126.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 56/74 of epoch 1 complete. Loss : 0.01580172740588231 \n",
      "\n",
      "Iteration 70/74 of epoch 1 complete. Loss : 0.017003095841833522 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 97.94it/s] \n",
      "100%|██████████| 19/19 [00:00<00:00, 255.17it/s]\n",
      " 19%|█▉        | 14/74 [00:00<00:00, 128.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 complete! Validation Loss : 0.02196855948453671\n",
      "Epoch 1 complete! Validation Accuracy : 0.9942434210526315\n",
      "Best validation loss improved from inf to 0.02196855948453671\n",
      "\n",
      "\n",
      "Iteration 14/74 of epoch 2 complete. Loss : 0.0168457172278847 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 53/74 [00:00<00:00, 127.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 28/74 of epoch 2 complete. Loss : 0.01341478613072208 \n",
      "\n",
      "Iteration 42/74 of epoch 2 complete. Loss : 0.014344906201586127 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 127.40it/s]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 56/74 of epoch 2 complete. Loss : 0.016725494027403847 \n",
      "\n",
      "Iteration 70/74 of epoch 2 complete. Loss : 0.014220840730039137 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 243.47it/s]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 complete! Validation Loss : 0.02946852230908055\n",
      "Epoch 2 complete! Validation Accuracy : 0.9901315789473685\n",
      "Evaluating on the testset\n",
      "SPLIT 3\n",
      "TRAIN: (9413,) TEST: (2353,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 26/74 [00:00<00:00, 124.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 14/74 of epoch 1 complete. Loss : 0.0125357267513339 \n",
      "\n",
      "Iteration 28/74 of epoch 1 complete. Loss : 0.013013174956930535 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 58/74 [00:00<00:00, 110.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 42/74 of epoch 1 complete. Loss : 0.014722976999889528 \n",
      "\n",
      "Iteration 56/74 of epoch 1 complete. Loss : 0.014531203179753252 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 111.31it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 195.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 70/74 of epoch 1 complete. Loss : 0.013911317169134105 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 13/74 [00:00<00:00, 123.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 complete! Validation Loss : 0.018262424677806467\n",
      "Epoch 1 complete! Validation Accuracy : 0.9946546052631579\n",
      "Best validation loss improved from inf to 0.018262424677806467\n",
      "\n",
      "\n",
      "Iteration 14/74 of epoch 2 complete. Loss : 0.012700162495353393 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 52/74 [00:00<00:00, 124.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 28/74 of epoch 2 complete. Loss : 0.012001705023327045 \n",
      "\n",
      "Iteration 42/74 of epoch 2 complete. Loss : 0.014362677599170379 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 125.23it/s]\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 56/74 of epoch 2 complete. Loss : 0.012224271427839994 \n",
      "\n",
      "Iteration 70/74 of epoch 2 complete. Loss : 0.014901498349250428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 249.33it/s]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 complete! Validation Loss : 0.0198421916973434\n",
      "Epoch 2 complete! Validation Accuracy : 0.993421052631579\n",
      "Evaluating on the testset\n",
      "SPLIT 4\n",
      "TRAIN: (9413,) TEST: (2353,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 28/74 [00:00<00:00, 138.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 14/74 of epoch 1 complete. Loss : 0.013004016131162643 \n",
      "\n",
      "Iteration 28/74 of epoch 1 complete. Loss : 0.012139848516588765 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 56/74 [00:00<00:00, 135.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 42/74 of epoch 1 complete. Loss : 0.010923682379403285 \n",
      "\n",
      "Iteration 56/74 of epoch 1 complete. Loss : 0.010240740591793187 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 134.53it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 247.00it/s]\n",
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 70/74 of epoch 1 complete. Loss : 0.012465168655450855 \n",
      "\n",
      "Epoch 1 complete! Validation Loss : 0.030837297611134618\n",
      "Epoch 1 complete! Validation Accuracy : 0.9894686493018261\n",
      "Best validation loss improved from inf to 0.030837297611134618\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 27/74 [00:00<00:00, 129.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 14/74 of epoch 2 complete. Loss : 0.009976477495261602 \n",
      "\n",
      "Iteration 28/74 of epoch 2 complete. Loss : 0.011624741334734219 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 66/74 [00:00<00:00, 126.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 42/74 of epoch 2 complete. Loss : 0.01352447534113058 \n",
      "\n",
      "Iteration 56/74 of epoch 2 complete. Loss : 0.010285668066769307 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:00<00:00, 126.61it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 242.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 70/74 of epoch 2 complete. Loss : 0.01106503973382392 \n",
      "\n",
      "Epoch 2 complete! Validation Loss : 0.027586552400239987\n",
      "Epoch 2 complete! Validation Accuracy : 0.990702201933405\n",
      "Best validation loss improved from 0.030837297611134618 to 0.027586552400239987\n",
      "\n",
      "Evaluating on the testset\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement K-Fold splits model\n",
    "batch_size = 128\n",
    "ctr = 0\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "for train_index, test_index in kf.split(source_multimodal_tensor):\n",
    "    print(\"SPLIT\", ctr)\n",
    "    ctr += 1\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)\n",
    "    train_tar, test_tar = target_multimodal_tensor[train_index], target_multimodal_tensor[test_index]\n",
    "    train_src, test_src = source_multimodal_tensor[train_index], source_multimodal_tensor[test_index]\n",
    "    train_emotion, test_emotion = emotion_source_tensor[train_index], emotion_source_tensor[test_index]\n",
    "    train_labels, test_labels = labels_tensor[train_index], labels_tensor[test_index]\n",
    "    train_data, train_sampler, train_dataloader = get_data_loader(batch_size, train_tar, train_src, train_emotion, train_labels, 'train')\n",
    "    test_data, test_sampler, test_dataloader = get_data_loader(batch_size, test_tar, test_src, test_emotion, test_labels, 'val')\n",
    "    optimizer, scheduler = get_optimizer_scheduler(name, class_model, len(train_dataloader), epochs, lr)\n",
    "    model, model_name = train_model(class_model, criterion, optimizer, lr, scheduler, train_dataloader, test_dataloader, epochs, iters_to_accumulate)\n",
    "    predictions, true_labels = evaluate(test_dataloader, model, path_to_model = '', load = False)\n",
    "    all_predictions.extend(predictions)\n",
    "    all_true_labels.extend(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvalidate_nv_em_ce_rbert_full Multi-Modal Classification accuracy is\n",
      "98.82712901580825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.98      0.99      0.99      4950\n",
      "        real       0.99      0.99      0.99      6816\n",
      "\n",
      "    accuracy                           0.99     11766\n",
      "   macro avg       0.99      0.99      0.99     11766\n",
      "weighted avg       0.99      0.99      0.99     11766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the final results\n",
    "print(model_name, 'Multi-Modal Classification accuracy is')\n",
    "print(metrics.accuracy_score(all_true_labels, all_predictions)*100)\n",
    "print(classification_report(all_true_labels, all_predictions, target_names = ['fake', 'real']))\n",
    "# Converting to csv\n",
    "# Removed transpose - check if actually required\n",
    "clsf_report = pd.DataFrame(classification_report(y_true = all_true_labels, y_pred = all_predictions, output_dict=True, target_names = ['fake', 'real']))\n",
    "clsf_report.to_csv(str('saved_models/'+model_name+'.csv'), index= True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "112ac2046fa01f929d29fd747457323c8422411859b530c12136f6127f223c24"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('newnisbert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
