{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./UnBiasedEmo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sda/rina_1921cs13/anaconda3/envs/newnisbert/lib/python3.6/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(1)\n",
    "import csv\n",
    "import cv2\n",
    "import os,re, codecs\n",
    "import tensorflow.keras.metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from tensorflow.python.keras.layers.merge import Concatenate, Average, concatenate\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from numpy import asarray,zeros\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('always') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lines to run the code on GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "K.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image ids 3045\n",
      "Unique images 2123\n"
     ]
    }
   ],
   "source": [
    "#--------------------Image Input-------------------------------------------\n",
    "train = pd.read_csv('.//UnBiasedEmo/data.csv')\n",
    "\n",
    "image_id=train.image_id.values\n",
    "image_id=image_id.tolist()\n",
    "print('Total number of image ids', len(image_id))\n",
    "unique_images = list(np.unique(image_id))\n",
    "num_unique_image = len(unique_images)\n",
    "print('Unique images', num_unique_image) # Some images are repeated and have the more than one emotion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger/ guy\n",
      "anger/ dog\n",
      "anger/ crowd\n",
      "anger/ girl\n",
      "anger/ horse\n",
      "anger/ couple\n",
      "anger/ baby\n",
      "anger/ athletes\n",
      "anger/ family\n",
      "anger/ soldier\n",
      "anger/ tiger\n",
      "anger/ teenager\n",
      "anger/ lion\n",
      "anger/ teacher\n",
      "anger/ cat\n",
      "fear/ guy\n",
      "fear/ dog\n",
      "fear/ girl\n",
      "fear/ couple\n",
      "fear/ scenery\n",
      "fear/ baby\n",
      "fear/ family\n",
      "fear/ cat\n",
      "joy/ events\n",
      "joy/ guy\n",
      "joy/ dog\n",
      "joy/ girl\n",
      "joy/ scenery\n",
      "joy/ baby\n",
      "joy/ athletes\n",
      "joy/ family\n",
      "joy/ park\n",
      "joy/ teenager\n",
      "joy/ teacher\n",
      "joy/ cat\n",
      "love/ dog\n",
      "love/ people\n",
      "love/ couple\n",
      "love/ scenery\n",
      "love/ baby\n",
      "love/ animals\n",
      "love/ teenager\n",
      "love/ cat\n",
      "sadness/ guy\n",
      "sadness/ girl\n",
      "sadness/ people\n",
      "sadness/ couple\n",
      "sadness/ scenery\n",
      "sadness/ baby\n",
      "sadness/ park\n",
      "sadness/ teenager\n",
      "sadness/ group\n",
      "surprise/ people\n",
      "surprise/ couple\n",
      "surprise/ scenery\n",
      "surprise/ baby\n",
      "surprise/ family\n",
      "surprise/ cat\n",
      "(3045, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# example of loading an image with the Keras API\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19,VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "image_embed = []\n",
    "item_lab = [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]\n",
    "item = [\"athletes\",\"baby\", \"couple\",\"cat\",\"crowd\",\"dog\",\"family\",\"girl\",\"guy\",\"horse\",\"lion\",\"soldier\",\"teacher\",\"teenager\",\"tiger\",\"people\",\"scenery\", \"events\", \"park\", \"animals\", \"group\"]\n",
    "\n",
    "label =[]\n",
    "for num, i in enumerate(item_lab):\n",
    "    fol_dir = os.path.join('.//UnBiasedEmo/images/', i)\n",
    "    sub_dirs = os.listdir(fol_dir)\n",
    "    for j in sub_dirs:\n",
    "        if os.path.isdir(\".//UnBiasedEmo/images/\"+i+\"/\"+j):\n",
    "            print(i+'/',j)\n",
    "            for k in os.listdir(\".//UnBiasedEmo/images/\"+i+\"/\"+j):\n",
    "                img = load_img(\".//UnBiasedEmo/images/\"+i+\"/\"+j+\"/\"+k,target_size=(224, 224))\t\n",
    "                img = img_to_array(img)\n",
    "                img = preprocess_input(img)\n",
    "                image_embed.append(img)\n",
    "                label.append(num)\n",
    "        else:\n",
    "            print(\"path does not exist\")\n",
    "\n",
    "data = np.array(image_embed)\n",
    "label_arr = np.array(label)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image data shape (3045, 224, 224, 3)\n",
      "labels shape (3045,)\n"
     ]
    }
   ],
   "source": [
    "print('image data shape', data.shape)\n",
    "print('labels shape', label_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "np.save('.//UnBiasedEmo/data.npy', data)\n",
    "np.save('.//UnBiasedEmo/label.npy', label_arr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4396559e1bf5c32d41ffba8c548c213f47855d2d4ac82024dddc5ba3ffea815"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('newnisbert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
