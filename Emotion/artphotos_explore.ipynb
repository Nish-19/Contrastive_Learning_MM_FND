{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sda/rina_1921cs13/anaconda3/envs/newnisbert/lib/python3.6/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(1)\n",
    "import csv\n",
    "import cv2\n",
    "import os,re, codecs\n",
    "import tensorflow.keras.metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from tensorflow.python.keras.layers.merge import Concatenate, Average, concatenate\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from numpy import asarray,zeros\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('always') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lines to run the code on GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "K.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n"
     ]
    }
   ],
   "source": [
    "artphotos_dir = './testImages_artphoto/'\n",
    "dir_contents = os.listdir(artphotos_dir)\n",
    "print(len(dir_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReadMe.rtf\n",
      ".DS_Store\n",
      "806\n",
      "Counter({'sad': 166, 'fear': 115, 'excitement': 105, 'awe': 102, 'amusement': 101, 'anger': 77, 'disgust': 70, 'contentment': 70})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_images = 0\n",
    "count_labels = Counter()\n",
    "for img_file in dir_contents:\n",
    "    if '.jpg' in img_file:\n",
    "        img_label = img_file.split('_')[0]\n",
    "        count_labels[img_label] += 1 \n",
    "        count_images += 1\n",
    "    else:\n",
    "        print(img_file)\n",
    "print(count_images) # 806 images are there in total\n",
    "print(count_labels) # Printing labels count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Categorize emotions\n",
    "# (Original) True Emotions - anticipation, sadness, joy and trust\n",
    "# (Original) False Emotions - Fear, Disgust, Surprise\n",
    "# (Here) True Emotions - sad, contenment (236)\n",
    "true_emotions = ['sad', 'contentment'] # Label 1\n",
    "# (Here) False Emotions - fear, excitement, awe, amusement, anger, disgust (570)\n",
    "false_emotions = ['fear', 'excitement', 'awe', 'amusement', 'anger', 'disgust'] # Label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not processed ReadMe.rtf\n",
      "Not processed .DS_Store\n",
      "(806, 224, 224, 3)\n",
      "(806,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19,VGG16\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "image_embed = []\n",
    "label =[]\n",
    "for img_file in dir_contents:\n",
    "    if '.jpg' in img_file:\n",
    "        img_path = os.path.join(artphotos_dir, img_file)\n",
    "        img_label = img_file.split('_')[0]\n",
    "        img = load_img(img_path, target_size=(224, 224))\t\n",
    "        img = img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        image_embed.append(img)\n",
    "        if img_label in true_emotions:\n",
    "            label.append(1)\n",
    "        elif img_label in false_emotions:\n",
    "            label.append(0)\n",
    "        else:\n",
    "            print(\"you missed something\")\n",
    "    else:\n",
    "        print('Not processed', img_file)\n",
    "\n",
    "data = np.array(image_embed)\n",
    "label_arr = np.array(label)\n",
    "print(data.shape)\n",
    "print(label_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "np.save(os.path.join(artphotos_dir, 'data.npy'), data)\n",
    "np.save(os.path.join(artphotos_dir, 'label.npy'), label_arr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4396559e1bf5c32d41ffba8c548c213f47855d2d4ac82024dddc5ba3ffea815"
  },
  "kernelspec": {
   "display_name": "Python 3.6.11 64-bit ('newnisbert': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
